{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.llms import AzureOpenAI\n",
    "\n",
    "from langchain.vectorstores import AzureSearch\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "import azure.identity\n",
    "\n",
    "\n",
    "import pyodbc\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to LLM and Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Establishing connection with GPT-4 Turbo OpenAI LLM.\n",
      "Established connection with GPT-4 Turbo OpenAI LLM.\n",
      "Fetching GPT-4 OpenAI Embeddings.\n",
      "Fetched with GPT-4 OpenAI Embeddings.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_openai import AzureOpenAI\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "\n",
    "load_dotenv() # Load environment variables from the .env file\n",
    "deployment_name                       = \"CART\"\n",
    "embedding_deployment_name             = os.getenv(\"embedding_deployment_name\") \n",
    "AZURE_OPENAI_API_TYPE                 = os.getenv(\"AZURE_OPENAI_API_TYPE\")\n",
    "AZURE_OPENAI_API_KEY                  = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_ENDPOINT                 = os.getenv(\"AZURE_OPENAI_API_BASE\")\n",
    "AZURE_OPENAI_API_VERSION              = os.getenv(\"AZURE_OPENAI_API_VERSION_CHAT\")\n",
    "AZURE_OPENAI_API_VERSION_EMBEDDING    = os.getenv(\"AZURE_OPENAI_API_VERSION_EMBEDDING\")\n",
    "\n",
    "os.environ[\"OPENAI_API_VERSION\"]      = AZURE_OPENAI_API_VERSION\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"]   = AZURE_OPENAI_ENDPOINT\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"]    = AZURE_OPENAI_API_KEY\n",
    "\n",
    "print(\"Establishing connection with GPT-4 Turbo OpenAI LLM.\")\n",
    "llm = AzureChatOpenAI(\n",
    "                        deployment_name = deployment_name,\n",
    "                        temperature=0.0\n",
    "                    )\n",
    "print(\"Established connection with GPT-4 Turbo OpenAI LLM.\")\n",
    "\n",
    "print(\"Fetching GPT-4 OpenAI Embeddings.\")\n",
    "embeddings_model = AzureOpenAIEmbeddings(\n",
    "                                            model          = \"text-embedding-ada-002\",\n",
    "                                            azure_endpoint = AZURE_OPENAI_ENDPOINT,\n",
    "                                            api_key        = AZURE_OPENAI_API_KEY,\n",
    "                                            openai_api_version = AZURE_OPENAI_API_VERSION_EMBEDDING\n",
    "                                        )\n",
    "print(\"Fetched with GPT-4 OpenAI Embeddings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Why did the tomato turn red?\\n\\nBecause it saw the salad dressing!' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 13, 'total_tokens': 27, 'completion_tokens_details': None}, 'model_name': 'gpt-35-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-972bff2c-73ce-43f3-aa4e-b46f144b8300-0'\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(\"Tell me a joke.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings_model.embed_query(\"Tell me a joke.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Azure AI Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Azure Search.\n",
      "AzureSearch client initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "AZURE_COGNITIVE_SEARCH_SERVICE_NAME     = os.getenv(\"AZURE_COGNITIVE_SEARCH_SERVICE_NAME\")\n",
    "AZURE_COGNITIVE_SEARCH_API_KEY          = os.getenv(\"AZURE_COGNITIVE_SEARCH_API_KEY\")\n",
    "AZURE_COGNITIVE_SEARCH_INDEX_NAME       = os.getenv(\"AZURE_COGNITIVE_SEARCH_INDEX_NAME\")\n",
    "AZURE_COGNITIVE_SEARCH_SERVICE_ENDPOINT =  f\"https://{AZURE_COGNITIVE_SEARCH_SERVICE_NAME}.search.windows.net\"\n",
    "\n",
    "\n",
    "print(\"Initializing Azure Search.\")\n",
    "\n",
    "Azure_Client = AzureSearch(\n",
    "                                 azure_search_endpoint = AZURE_COGNITIVE_SEARCH_SERVICE_ENDPOINT,\n",
    "                                 azure_search_key      = AZURE_COGNITIVE_SEARCH_API_KEY,\n",
    "                                 index_name            = AZURE_COGNITIVE_SEARCH_INDEX_NAME,\n",
    "                                 embedding_function    = embeddings_model.embed_query ,\n",
    "                          )\n",
    "\n",
    "print(\"AzureSearch client initialized successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load PDF into Azure AI Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reg_AA_Path = r\"C:\\GenAI\\CART-Azure-IAAS\\regulations\\Reg_AA (Unfair or Deceptive Acts or Practices)\\archive\\Regulation_AA.pdf\"\n",
    "\n",
    "Reg_AA_Loader = PyPDFLoader(Reg_AA_Path, extract_images=True)\n",
    "Reg_AA_Documents = Reg_AA_Loader.load()\n",
    "\n",
    "# Splitting the documents into chunks\n",
    "Text_Splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 200)\n",
    "Reg_AA_Text = Text_Splitter.split_documents(Reg_AA_Documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading document chunks to Azure Cognitive Search...\n",
      "Successfully uploaded 61 chunks to Azure Cognitive Search.\n"
     ]
    }
   ],
   "source": [
    "# Assuming the previous code has already established the connection to Azure Cognitive Search and split the PDF into chunks\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "# Assuming Reg_AA_Text already contains the split documents\n",
    "# Add metadata to each chunk\n",
    "for i, chunk in enumerate(Reg_AA_Text):\n",
    "    # Example of metadata: you can add custom fields like source, page number, etc.\n",
    "    chunk.metadata = {\n",
    "        \"source\": Reg_AA_Path,\n",
    "        \"document_type\": \"Regulation\",\n",
    "        \"regulation_name\": \"Reg AA\",\n",
    "        \"chunk_index\": i  # Add a chunk index to track chunks\n",
    "    }\n",
    "\n",
    "# Insert the chunks (with metadata) into the Azure Cognitive Search index\n",
    "print(\"Uploading document chunks to Azure Cognitive Search...\")\n",
    "\n",
    "# Convert the documents to the format AzureSearch expects, which is typically a list of `Document` objects\n",
    "azure_documents = [\n",
    "    Document(page_content=doc.page_content, metadata=doc.metadata) for doc in Reg_AA_Text\n",
    "]\n",
    "\n",
    "# Add the documents to the Azure Search index\n",
    "Azure_Client.add_documents(azure_documents)\n",
    "\n",
    "print(f\"Successfully uploaded {len(azure_documents)} chunks to Azure Cognitive Search.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "or practice has occurred and whether further supervisory or enforcement actions are appropriate.  \n",
      "General Guidanc e \n",
      "Based on the results of the risk assessment of  the entity, e xaminers should review for potential \n",
      "unfair, deceptive, or abusive acts or practices , taking into account an entityâ€™s  marketing \n",
      "programs , product and service mix, customer base , and other factor s, as appropriate.  Even if the \n",
      "risk assessment has not identified potential unfair, deceptive , or abusive acts or practices, \n",
      "examiner s should be alert throughout an examination for situations that warrant review.  \n",
      "1. Document Review  \n",
      "a. To initially identify potential areas of UDAAP concerns, o btain and review copies of the \n",
      "following to the extent relevant to the examination:  \n",
      "b. Training materia ls. \n",
      "c. Lists of products and services, including descriptions, fee structure , disclosures, notices, \n",
      "agreements, and periodic and account statements .\n"
     ]
    }
   ],
   "source": [
    "docs = Azure_Client.similarity_search(\n",
    "    query=\"What is RegAA about?\",\n",
    "    k=3,\n",
    "    search_type=\"similarity\",\n",
    ")\n",
    "print(docs[1].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reg_AA_prompt_template = \"\"\"\n",
    "                                    You are an expert in CFPB regulations. Given data is the context of Regulation AA.\n",
    "                                    Context:{context}\n",
    "                                    Does the following complaint fall under Regulation AA?\n",
    "                                    Complaint:\"{complaint}\"       \n",
    "            \n",
    "                                    Answer with 'Yes' or 'No'. \n",
    "\n",
    "                                    Provide an explanation. Make sure the explanation ends in four or less that four sentences.\n",
    "                                    Explanation:\n",
    "                                    \n",
    "                                    Please return the answer in the following dictionary format:\n",
    "                                    {{\"Answer\": \"Yes\" or \"No\", \"Explanation\": \"Your explanation here.\"}}\n",
    "                                \"\"\"\n",
    "\n",
    "Reg_AA_PROMPT      = PromptTemplate(template=Reg_AA_prompt_template, input_variables=[\"context\", \"complaint\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a chain and a retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Retriever\n",
    "Reg_AA_Retriever = Azure_Client.as_retriever()\n",
    "\n",
    "# Creating a chain\n",
    "REG_AA_chain = (\n",
    "                    {\"context\": Reg_AA_Retriever,\"complaint\": RunnablePassthrough()}\n",
    "                    | Reg_AA_PROMPT\n",
    "                    | llm\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying complaints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to SQL Server.\n",
      "Established  Connection to the CART Database in SQL Server.\n"
     ]
    }
   ],
   "source": [
    "############################################################# Connecting to SQL Server ################################################################\n",
    "print(\"Connecting to SQL Server.\")\n",
    "server    = 'DESKTOP-VONKKUH'  # e.g., 'localhost\\SQLEXPRESS'\n",
    "database  = 'CART'  # e.g., 'CART_DB'\n",
    "driver    = '{ODBC Driver 17 for SQL Server}'  # Ensure you have the correct ODBC driver installed\n",
    "conn      = pyodbc.connect(f'DRIVER={driver};SERVER={server};DATABASE={database};Trusted_Connection=yes;')\n",
    "print(\"Established  Connection to the CART Database in SQL Server.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I never agreed to information sharing with a company I never agreed or signed a legal binding contract with XXXXXXXX XXXX I never signed a contract with this company My information was shared by Navy federal without my permission XXXX stole my information They do not have my permission to report inaccurate accounts with balances Thats a charge off And late payments is violated my consumer rights'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complaint_text = \"I never agreed to information sharing with a company I never agreed or signed a legal binding contract with XXXXXXXX XXXX I never signed a contract with this company My information was shared by Navy federal without my permission XXXX stole my information They do not have my permission to report inaccurate accounts with balances Thats a charge off And late payments is violated my consumer rights\"\n",
    "complaint_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_complaint(complaint_text,chain):\n",
    "    response = chain.invoke(complaint_text).content\n",
    "    response = json.loads(response)\n",
    "    if response['Answer'].lower() == \"yes\":\n",
    "        answer = 1\n",
    "    elif response['Answer'].lower() == \"no\":\n",
    "        answer = 0\n",
    "    else:\n",
    "        answer = None\n",
    "    regulation_explanation = response[\"Explanation\"]\n",
    "    return answer, regulation_explanation\n",
    "\n",
    "chain = REG_AA_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Answer': 'No',\n",
       " 'Explanation': 'The complaint does not directly relate to any of the specific standards outlined in Regulation AA. It appears to be more focused on issues related to information sharing and inaccurate reporting, which may fall under other regulations or laws.'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(complaint_text).content\n",
    "response = json.loads(response)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer, regulation_explanation = classify_complaint(complaint_text,chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The complaint does not directly relate to any of the specific standards outlined in Regulation AA. It appears to be more focused on issues related to information sharing and inaccurate reporting, which may fall under other regulations or laws.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regulation_explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresponse\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'response' is not defined"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"content='Answer: Yes\\\\n\\\\nExplanation: The complaint involves issues related to information sharing without clear justification, inaccurate reporting of accounts with balances, and violation of consumer rights, which are all covered under Regulation AA.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 1383, 'total_tokens': 1422, 'completion_tokens_details': None}, 'model_name': 'gpt-35-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-cecf2552-4dcc-41ba-835f-8b01f24d5e2e-0'\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanation = str(response) \n",
    "explanation = explanation.replace(\"\\n\\nExplanation:\",'')\n",
    "explanation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
