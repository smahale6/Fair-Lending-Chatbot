{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9b4b4c7-a9ed-4697-abfc-6013b47d4d49",
   "metadata": {},
   "source": [
    "### Installing Neccessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4abfddc3-074e-41f1-b680-0e5c68ad954e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_openai import AzureOpenAI\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.llms import AzureOpenAI\n",
    "\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "import azure.identity\n",
    "\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "import os\n",
    "import pyodbc\n",
    "import json\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef16fa6-b24a-426b-8dcc-4708ce5e5070",
   "metadata": {},
   "source": [
    "### Connecting To Azure Open AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffb1a974-3078-4c45-8fa1-02ee35d2fd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Establishing connection with GPT-4 Turbo OpenAI LLM.\n",
      "Established connection with GPT-4 Turbo OpenAI LLM.\n",
      "Fetching GPT-4 OpenAI Embeddings.\n",
      "Fetched with GPT-4 OpenAI Embeddings.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv() # Load environment variables from the .env file\n",
    "deployment_name                       = \"CART\"\n",
    "embedding_deployment_name             = os.getenv(\"embedding_deployment_name\") \n",
    "AZURE_OPENAI_API_TYPE                 = os.getenv(\"AZURE_OPENAI_API_TYPE\")\n",
    "AZURE_OPENAI_API_KEY                  = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_ENDPOINT                 = os.getenv(\"AZURE_OPENAI_API_BASE\")\n",
    "AZURE_OPENAI_API_VERSION              = os.getenv(\"AZURE_OPENAI_API_VERSION_CHAT\")\n",
    "AZURE_OPENAI_API_VERSION_EMBEDDING    = os.getenv(\"AZURE_OPENAI_API_VERSION_EMBEDDING\")\n",
    "\n",
    "os.environ[\"OPENAI_API_VERSION\"]      = AZURE_OPENAI_API_VERSION\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"]   = AZURE_OPENAI_ENDPOINT\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"]    = AZURE_OPENAI_API_KEY\n",
    "\n",
    "print(\"Establishing connection with GPT-4 Turbo OpenAI LLM.\")\n",
    "llm = AzureChatOpenAI(\n",
    "                        deployment_name = deployment_name,\n",
    "                        temperature=0.0\n",
    "                    )\n",
    "print(\"Established connection with GPT-4 Turbo OpenAI LLM.\")\n",
    "\n",
    "\n",
    "print(\"Fetching GPT-4 OpenAI Embeddings.\")\n",
    "embeddings_model = AzureOpenAIEmbeddings(\n",
    "                                            model          = \"text-embedding-ada-002\",\n",
    "                                            azure_endpoint = AZURE_OPENAI_ENDPOINT,\n",
    "                                            api_key        = AZURE_OPENAI_API_KEY,\n",
    "                                            openai_api_version = AZURE_OPENAI_API_VERSION_EMBEDDING\n",
    "                                        )\n",
    "print(\"Fetched with GPT-4 OpenAI Embeddings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6add649-96bd-4d4e-aa07-0092efaba11c",
   "metadata": {},
   "source": [
    "### Initializing Pinecone Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5d77028-9d1a-43cd-99ce-57ea39318f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing the connection to the Pinecone Vector Database.\n",
      "Initialized the connection to the Pinecone Vector Database.\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing the connection to the Pinecone Vector Database.\")\n",
    "load_dotenv()  # Load environment variables from the .env file\n",
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n",
    "PINECONE_HOST_NAME = os.getenv('PINECONE_HOST_NAME')\n",
    "pc = Pinecone(api_key = PINECONE_API_KEY)\n",
    "pc\n",
    "print(\"Initialized the connection to the Pinecone Vector Database.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78178c8d-36e0-480d-a0e4-2f89f69b5c7d",
   "metadata": {},
   "source": [
    "### Connecting to Google News API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c029ca9-6816-4b2b-b92e-3ce1467c0bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Source</th>\n",
       "      <th>Description</th>\n",
       "      <th>URL</th>\n",
       "      <th>Published At</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Immigrant Underemployment Contributes to Menta...</td>\n",
       "      <td>Robert T Muller Ph.D.</td>\n",
       "      <td>Psychology Today</td>\n",
       "      <td>Immigrants and refugees often struggle to find...</td>\n",
       "      <td>https://www.psychologytoday.com/intl/blog/talk...</td>\n",
       "      <td>2024-11-17T16:05:29Z</td>\n",
       "      <td>When we fall prey to perfectionism...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ward Scull, 81, passionate Virginia advocate f...</td>\n",
       "      <td>DAVE RESS Richmond Times-Dispatch</td>\n",
       "      <td>Richmond.com</td>\n",
       "      <td>Ward Scull fought the long, hard battle to sto...</td>\n",
       "      <td>https://richmond.com/news/state-regional/ward-...</td>\n",
       "      <td>2024-11-15T18:33:00Z</td>\n",
       "      <td>E-edition PLUS unlimited articles &amp; videos Per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mortgage access for Black buyers blamed for wi...</td>\n",
       "      <td>Marian McPherson</td>\n",
       "      <td>Inman</td>\n",
       "      <td>Mortgage discrimination and appraisal bias are...</td>\n",
       "      <td>https://www.inman.com/2024/11/14/mortgage-acce...</td>\n",
       "      <td>2024-11-14T19:03:45Z</td>\n",
       "      <td>Mortgage discrimination and appraisal bias are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On Building Git for Lawyers</td>\n",
       "      <td>Jordan Bryan</td>\n",
       "      <td>Substack.com</td>\n",
       "      <td>Over this past weekend, Twitter discovered the...</td>\n",
       "      <td>https://jordanbryan.substack.com/p/on-building...</td>\n",
       "      <td>2024-11-14T15:48:45Z</td>\n",
       "      <td>Over this past weekend, Twitter discovered the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Project 2025 Document Mentions Trump's Name Mo...</td>\n",
       "      <td>Aleksandra Wrona</td>\n",
       "      <td>Snopes.com</td>\n",
       "      <td>U.S. President-elect Donald Trump's name is li...</td>\n",
       "      <td>https://www.snopes.com//fact-check/trump-proje...</td>\n",
       "      <td>2024-11-14T14:00:00Z</td>\n",
       "      <td>About this rating  The word \"Trump\" appears 31...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>If You Like Being Ripped Off By Comcast, You’l...</td>\n",
       "      <td>Karl Bode</td>\n",
       "      <td>Techdirt</td>\n",
       "      <td>Current FCC Commissioner Brendan Carr has spen...</td>\n",
       "      <td>https://www.techdirt.com/2024/11/13/if-you-lik...</td>\n",
       "      <td>2024-11-13T13:31:35Z</td>\n",
       "      <td>Predictions Current FCC Commissioner Brendan C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Court: Connecticut High School Females’ Discri...</td>\n",
       "      <td>James Nault</td>\n",
       "      <td>Legalinsurrection.com</td>\n",
       "      <td>Connecticut federal court rules that Plaintiff...</td>\n",
       "      <td>https://legalinsurrection.com/2024/11/court-co...</td>\n",
       "      <td>2024-11-13T00:00:29Z</td>\n",
       "      <td>This website is using a security service to pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CAMEO CEO Carolina Martinez: The Untapped Powe...</td>\n",
       "      <td>Rhett Buttle, Contributor, \\n Rhett Buttle, Co...</td>\n",
       "      <td>Forbes</td>\n",
       "      <td>As CEO of CAMEO, Carolina Martinez leads a net...</td>\n",
       "      <td>https://www.forbes.com/sites/rhettbuttle/2024/...</td>\n",
       "      <td>2024-11-12T15:57:27Z</td>\n",
       "      <td>Carolina Martinez, CEO of the CAMEO Network A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Must the Professor Crusade? W. Ralph Eubanks o...</td>\n",
       "      <td>W. Ralph Eubanks</td>\n",
       "      <td>Lithub.com</td>\n",
       "      <td>“I’ve seen this movie before” is what I though...</td>\n",
       "      <td>https://lithub.com/must-the-professor-crusade-...</td>\n",
       "      <td>2024-11-12T13:41:54Z</td>\n",
       "      <td>Ive seen this movie before is what I thought a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dis/Trusting the Institution(s) of Literature</td>\n",
       "      <td>groenlat@tcd.ie</td>\n",
       "      <td>Upenn.edu</td>\n",
       "      <td>updated: \\r\\nTuesday, November 12, 2024 - 5:41...</td>\n",
       "      <td>http://call-for-papers.sas.upenn.edu/cfp/2024/...</td>\n",
       "      <td>2024-11-12T10:19:01Z</td>\n",
       "      <td>Jump to navigation Call for Papers a service p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Immigrant Underemployment Contributes to Menta...   \n",
       "1  Ward Scull, 81, passionate Virginia advocate f...   \n",
       "2  Mortgage access for Black buyers blamed for wi...   \n",
       "3                        On Building Git for Lawyers   \n",
       "4  Project 2025 Document Mentions Trump's Name Mo...   \n",
       "5  If You Like Being Ripped Off By Comcast, You’l...   \n",
       "6  Court: Connecticut High School Females’ Discri...   \n",
       "7  CAMEO CEO Carolina Martinez: The Untapped Powe...   \n",
       "8  Must the Professor Crusade? W. Ralph Eubanks o...   \n",
       "9      Dis/Trusting the Institution(s) of Literature   \n",
       "\n",
       "                                              Author                 Source  \\\n",
       "0                              Robert T Muller Ph.D.       Psychology Today   \n",
       "1                  DAVE RESS Richmond Times-Dispatch           Richmond.com   \n",
       "2                                   Marian McPherson                  Inman   \n",
       "3                                       Jordan Bryan           Substack.com   \n",
       "4                                   Aleksandra Wrona             Snopes.com   \n",
       "5                                          Karl Bode               Techdirt   \n",
       "6                                        James Nault  Legalinsurrection.com   \n",
       "7  Rhett Buttle, Contributor, \\n Rhett Buttle, Co...                 Forbes   \n",
       "8                                   W. Ralph Eubanks             Lithub.com   \n",
       "9                                    groenlat@tcd.ie              Upenn.edu   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Immigrants and refugees often struggle to find...   \n",
       "1  Ward Scull fought the long, hard battle to sto...   \n",
       "2  Mortgage discrimination and appraisal bias are...   \n",
       "3  Over this past weekend, Twitter discovered the...   \n",
       "4  U.S. President-elect Donald Trump's name is li...   \n",
       "5  Current FCC Commissioner Brendan Carr has spen...   \n",
       "6  Connecticut federal court rules that Plaintiff...   \n",
       "7  As CEO of CAMEO, Carolina Martinez leads a net...   \n",
       "8  “I’ve seen this movie before” is what I though...   \n",
       "9  updated: \\r\\nTuesday, November 12, 2024 - 5:41...   \n",
       "\n",
       "                                                 URL          Published At  \\\n",
       "0  https://www.psychologytoday.com/intl/blog/talk...  2024-11-17T16:05:29Z   \n",
       "1  https://richmond.com/news/state-regional/ward-...  2024-11-15T18:33:00Z   \n",
       "2  https://www.inman.com/2024/11/14/mortgage-acce...  2024-11-14T19:03:45Z   \n",
       "3  https://jordanbryan.substack.com/p/on-building...  2024-11-14T15:48:45Z   \n",
       "4  https://www.snopes.com//fact-check/trump-proje...  2024-11-14T14:00:00Z   \n",
       "5  https://www.techdirt.com/2024/11/13/if-you-lik...  2024-11-13T13:31:35Z   \n",
       "6  https://legalinsurrection.com/2024/11/court-co...  2024-11-13T00:00:29Z   \n",
       "7  https://www.forbes.com/sites/rhettbuttle/2024/...  2024-11-12T15:57:27Z   \n",
       "8  https://lithub.com/must-the-professor-crusade-...  2024-11-12T13:41:54Z   \n",
       "9  http://call-for-papers.sas.upenn.edu/cfp/2024/...  2024-11-12T10:19:01Z   \n",
       "\n",
       "                                             Content  \n",
       "0              When we fall prey to perfectionism...  \n",
       "1  E-edition PLUS unlimited articles & videos Per...  \n",
       "2  Mortgage discrimination and appraisal bias are...  \n",
       "3  Over this past weekend, Twitter discovered the...  \n",
       "4  About this rating  The word \"Trump\" appears 31...  \n",
       "5  Predictions Current FCC Commissioner Brendan C...  \n",
       "6  This website is using a security service to pr...  \n",
       "7   Carolina Martinez, CEO of the CAMEO Network A...  \n",
       "8  Ive seen this movie before is what I thought a...  \n",
       "9  Jump to navigation Call for Papers a service p...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "def fetch_fair_lending_articles():\n",
    "    # Pull the NEWS_API_KEY from environment variables\n",
    "    NEWS_API_KEY = os.getenv('NEWS_API_KEY')\n",
    "\n",
    "    # Check if API key is available\n",
    "    if not NEWS_API_KEY:\n",
    "        raise ValueError(\"Please set the 'NEWS_API_KEY' environment variable.\")\n",
    "\n",
    "    # Define the base URL for NewsAPI\n",
    "    url = 'https://newsapi.org/v2/everything'\n",
    "\n",
    "    # Get the current date and the date from 7 days ago in YYYY-MM-DD format\n",
    "    current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "    last_week_date = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')\n",
    "\n",
    "    # Define the search query with specific keywords and phrases\n",
    "    search_query = (\n",
    "        '(\"fair lending\" OR \"disparate treatment\" OR \"overt discrimination\" OR '\n",
    "        '\"redlining\" OR \"mortgage discrimination\" OR \"banking discrimination\" OR '\n",
    "        '\"racial discrimination in banking\" OR \"lending bias\" OR \"credit discrimination\")'\n",
    "    )\n",
    "\n",
    "    # Set parameters for the request\n",
    "    params = {\n",
    "        'q': search_query,\n",
    "        'from': last_week_date,      # Start date (7 days ago)\n",
    "        'to': current_date,          # End date (today)\n",
    "        'language': 'en',            # Filter to English articles\n",
    "        'sortBy': 'publishedAt',     # Sort by recent publications\n",
    "        'pageSize': 10,              # Limit to 10 articles\n",
    "        'apiKey': NEWS_API_KEY\n",
    "    }\n",
    "\n",
    "    # Make the request to the NewsAPI\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    # Handle the response\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        articles = data.get('articles', [])\n",
    "        \n",
    "        # Extract relevant metadata and store it in a DataFrame\n",
    "        if articles:\n",
    "            articles_data = []\n",
    "\n",
    "            # Loop through each article to scrape and clean the full content\n",
    "            for article in articles:\n",
    "                article_data = {\n",
    "                    'Title': article.get('title'),\n",
    "                    'Author': article.get('author'),\n",
    "                    'Source': article.get('source', {}).get('name'),\n",
    "                    'Description': article.get('description'),\n",
    "                    'URL': article.get('url'),\n",
    "                    'Published At': article.get('publishedAt'),\n",
    "                }\n",
    "\n",
    "                # Scrape the full content of the article\n",
    "                article_url = article.get('url')\n",
    "                try:\n",
    "                    page = requests.get(article_url)\n",
    "                    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "                    # Extract paragraphs from the content\n",
    "                    paragraphs = soup.find_all('p')\n",
    "                    raw_content = ' '.join([para.get_text() for para in paragraphs])\n",
    "\n",
    "                    # Clean the text by removing non-ASCII characters\n",
    "                    cleaned_content = ''.join(filter(lambda x: x in set(map(chr, range(32, 127))), raw_content))\n",
    "\n",
    "                    article_data['Content'] = cleaned_content\n",
    "                except Exception as e:\n",
    "                    article_data['Content'] = f\"Error fetching content: {e}\"\n",
    "\n",
    "                articles_data.append(article_data)\n",
    "\n",
    "            # Create a DataFrame from the list of dictionaries\n",
    "            articles_df = pd.DataFrame(articles_data)\n",
    "            return articles_df\n",
    "        else:\n",
    "            print(\"No articles found for the last week.\")\n",
    "            return pd.DataFrame()  # Return an empty DataFrame if no articles found\n",
    "    else:\n",
    "        raise Exception(f\"Error: {response.status_code} - {response.text}\")\n",
    "\n",
    "# Example usage of the function\n",
    "articles_df = fetch_fair_lending_articles()\n",
    "articles_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11923f4-b17b-450b-abe7-4f1dad05b837",
   "metadata": {},
   "source": [
    "### Filtering to only Fair Lending data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4be90bc0-a3b7-4330-bd92-b37afcc16cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "import pandas as pd\n",
    "\n",
    "def evaluate_article_content(article_content, llm_chain):\n",
    "    try:\n",
    "        # Use the LLMChain to evaluate the article\n",
    "        response = llm_chain.run({\"article_content\": article_content})\n",
    "        # Determine if the response indicates the article is related\n",
    "        return \"yes\" in response.lower()\n",
    "    except Exception as e:\n",
    "        print(f\"Error while evaluating the article: {e}\")\n",
    "        return False\n",
    "\n",
    "def summarize_article_content(article_content, llm):\n",
    "    try:\n",
    "        # Prompt to summarize the content in 4-5 easy-to-understand sentences focusing on Fair Lending\n",
    "        summary_prompt = (\n",
    "            \"Please provide a concise summary of the following article in 4-5 sentences, focusing on the Fair Lending aspects of the article and making it easy to understand:\\n\\n\"\n",
    "            \"{article_content}\"\n",
    "        )\n",
    "        summary_template = PromptTemplate(input_variables=[\"article_content\"], template=summary_prompt)\n",
    "        summary_chain = LLMChain(llm=llm, prompt=summary_template)\n",
    "        response = summary_chain.run({\"article_content\": article_content})\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error while summarizing the article: {e}\")\n",
    "        return \"Error generating summary\"\n",
    "\n",
    "def evaluate_articles_with_langchain(articles_df, llm):\n",
    "    # Ensure the DataFrame has content to process\n",
    "    if articles_df.empty:\n",
    "        raise ValueError(\"The articles DataFrame is empty.\")\n",
    "\n",
    "    # Define the prompt template\n",
    "    prompt_template = (\n",
    "        \"Determine if the following article content is related to fair lending practices, \"\n",
    "        \"a financial institution, a bank, CFPB regulations, or any type of discrimination. \"\n",
    "        \"Please respond with 'Yes' if it is related, or 'No' if it is not:\\n\\n\"\n",
    "        \"{article_content}\"\n",
    "    )\n",
    "\n",
    "    # Create the LangChain PromptTemplate and LLMChain\n",
    "    prompt = PromptTemplate(input_variables=[\"article_content\"], template=prompt_template)\n",
    "    llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "    # Apply the evaluation function to each article content\n",
    "    articles_df['Is_Related'] = articles_df['Content'].apply(lambda x: evaluate_article_content(x, llm_chain))\n",
    "\n",
    "    # Apply the summary function to related articles only\n",
    "    articles_df['Content_Summary'] = articles_df.apply(\n",
    "        lambda row: summarize_article_content(row['Content'], llm) if row['Is_Related'] else \"\", axis=1\n",
    "    )\n",
    "    updated_articles_df = articles_df.loc[articles_df['Is_Related'] == True,:]\n",
    "    return updated_articles_df\n",
    "\n",
    "# Assuming articles_df is obtained using fetch_fair_lending_articles()\n",
    "updated_articles_df = evaluate_articles_with_langchain(articles_df, llm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f907b5df-f5a6-4afd-bdf6-f3b4e47e47e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Source</th>\n",
       "      <th>Description</th>\n",
       "      <th>URL</th>\n",
       "      <th>Published At</th>\n",
       "      <th>Content</th>\n",
       "      <th>Is_Related</th>\n",
       "      <th>Content_Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mortgage access for Black buyers blamed for wi...</td>\n",
       "      <td>Marian McPherson</td>\n",
       "      <td>Inman</td>\n",
       "      <td>Mortgage discrimination and appraisal bias are...</td>\n",
       "      <td>https://www.inman.com/2024/11/14/mortgage-acce...</td>\n",
       "      <td>2024-11-14T19:03:45Z</td>\n",
       "      <td>Mortgage discrimination and appraisal bias are...</td>\n",
       "      <td>True</td>\n",
       "      <td>Black homeownership gains are being eroded by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CAMEO CEO Carolina Martinez: The Untapped Powe...</td>\n",
       "      <td>Rhett Buttle, Contributor, \\n Rhett Buttle, Co...</td>\n",
       "      <td>Forbes</td>\n",
       "      <td>As CEO of CAMEO, Carolina Martinez leads a net...</td>\n",
       "      <td>https://www.forbes.com/sites/rhettbuttle/2024/...</td>\n",
       "      <td>2024-11-12T15:57:27Z</td>\n",
       "      <td>Carolina Martinez, CEO of the CAMEO Network A...</td>\n",
       "      <td>True</td>\n",
       "      <td>Carolina Martinez, CEO of the CAMEO Network, l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "2  Mortgage access for Black buyers blamed for wi...   \n",
       "7  CAMEO CEO Carolina Martinez: The Untapped Powe...   \n",
       "\n",
       "                                              Author  Source  \\\n",
       "2                                   Marian McPherson   Inman   \n",
       "7  Rhett Buttle, Contributor, \\n Rhett Buttle, Co...  Forbes   \n",
       "\n",
       "                                         Description  \\\n",
       "2  Mortgage discrimination and appraisal bias are...   \n",
       "7  As CEO of CAMEO, Carolina Martinez leads a net...   \n",
       "\n",
       "                                                 URL          Published At  \\\n",
       "2  https://www.inman.com/2024/11/14/mortgage-acce...  2024-11-14T19:03:45Z   \n",
       "7  https://www.forbes.com/sites/rhettbuttle/2024/...  2024-11-12T15:57:27Z   \n",
       "\n",
       "                                             Content  Is_Related  \\\n",
       "2  Mortgage discrimination and appraisal bias are...        True   \n",
       "7   Carolina Martinez, CEO of the CAMEO Network A...        True   \n",
       "\n",
       "                                     Content_Summary  \n",
       "2  Black homeownership gains are being eroded by ...  \n",
       "7  Carolina Martinez, CEO of the CAMEO Network, l...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_articles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6481430-7b21-4d66-90b3-668ccec9e4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_filename = \"updated_fair_lending_articles.csv\"\n",
    "updated_articles_df.to_csv(csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba66536-d6aa-4360-b599-3b37519779b9",
   "metadata": {},
   "source": [
    "### Loading into vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59f68ccd-68bf-48f4-a340-9067e6183367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error deleting vector ID article_0: (404)\n",
      "Reason: Not Found\n",
      "HTTP response headers: HTTPHeaderDict({'Date': 'Mon, 18 Nov 2024 16:10:15 GMT', 'Content-Type': 'application/json', 'Content-Length': '55', 'Connection': 'keep-alive', 'x-pinecone-request-latency-ms': '40', 'x-pinecone-request-id': '4317144196064810223', 'x-envoy-upstream-service-time': '41', 'server': 'envoy'})\n",
      "HTTP response body: {\"code\":5,\"message\":\"Namespace not found\",\"details\":[]}\n",
      "\n",
      "Successfully upserted vector with ID article_0 into Pinecone with metadata.\n",
      "Deleted existing vector with ID article_1.\n",
      "Successfully upserted vector with ID article_1 into Pinecone with metadata.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_type</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>source</th>\n",
       "      <th>published_at</th>\n",
       "      <th>summary</th>\n",
       "      <th>file_name</th>\n",
       "      <th>page_number</th>\n",
       "      <th>table_name</th>\n",
       "      <th>record_id</th>\n",
       "      <th>generation_date</th>\n",
       "      <th>month_year</th>\n",
       "      <th>document_version</th>\n",
       "      <th>load_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>news_article</td>\n",
       "      <td>Mortgage access for Black buyers blamed for wi...</td>\n",
       "      <td>Marian McPherson</td>\n",
       "      <td>Inman</td>\n",
       "      <td></td>\n",
       "      <td>Black homeownership gains are being eroded by ...</td>\n",
       "      <td>article</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>2024-11-18T11:10:20.207272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>news_article</td>\n",
       "      <td>CAMEO CEO Carolina Martinez: The Untapped Powe...</td>\n",
       "      <td>Rhett Buttle, Contributor, \\n Rhett Buttle, Co...</td>\n",
       "      <td>Forbes</td>\n",
       "      <td></td>\n",
       "      <td>Carolina Martinez, CEO of the CAMEO Network, l...</td>\n",
       "      <td>article</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>2024-11-18T11:10:20.207272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  document_type                                              title  \\\n",
       "0  news_article  Mortgage access for Black buyers blamed for wi...   \n",
       "1  news_article  CAMEO CEO Carolina Martinez: The Untapped Powe...   \n",
       "\n",
       "                                              author  source published_at  \\\n",
       "0                                   Marian McPherson   Inman                \n",
       "1  Rhett Buttle, Contributor, \\n Rhett Buttle, Co...  Forbes                \n",
       "\n",
       "                                             summary file_name page_number  \\\n",
       "0  Black homeownership gains are being eroded by ...   article               \n",
       "1  Carolina Martinez, CEO of the CAMEO Network, l...   article               \n",
       "\n",
       "  table_name record_id generation_date month_year  document_version  \\\n",
       "0                                                                 1   \n",
       "1                                                                 1   \n",
       "\n",
       "                load_datetime  \n",
       "0  2024-11-18T11:10:20.207272  \n",
       "1  2024-11-18T11:10:20.207272  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_pinecone import PineconeVectorStore as PineconeStore\n",
    "\n",
    "# Function to embed and load articles and other documents into Pinecone\n",
    "def embed_and_load_to_pinecone(updated_articles_df, additional_document, embeddings_model, pinecone_index):\n",
    "    # Initialize Pinecone using the latest Pinecone class\n",
    "    pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "    # Create or connect to the Pinecone index\n",
    "    if pinecone_index not in pc.list_indexes().names():\n",
    "        pc.create_index(\n",
    "            name=pinecone_index,\n",
    "            dimension=1536,  # Assuming embedding dimension is 1536\n",
    "            metric='cosine',  # Change metric if needed (e.g., euclidean, dotproduct)\n",
    "            spec=ServerlessSpec(\n",
    "                cloud='gcp',  # Replace with appropriate cloud provider if needed\n",
    "                region='us-west1'  # Replace with your Pinecone region\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Connect to the index and create PineconeStore with embeddings model\n",
    "    pinecone_store = PineconeStore(index_name=pinecone_index, embedding=embeddings_model)\n",
    "\n",
    "    # List to store metadata for DataFrame creation\n",
    "    metadata_list = []\n",
    "    load_datetime = datetime.now().isoformat()  # Capture the current datetime for loading\n",
    "\n",
    "    # Prepare texts and metadata for news articles from updated_articles_df\n",
    "    if not updated_articles_df.empty:\n",
    "        texts = updated_articles_df['Content'].tolist()\n",
    "        metadatas = updated_articles_df.apply(lambda row: {\n",
    "            \"document_type\": \"news_article\",\n",
    "            \"title\": row.get('Title', ''),\n",
    "            \"author\": row.get('Author', ''),\n",
    "            \"source\": row.get('Source', ''),\n",
    "            \"published_at\": row.get('Published_At', ''),\n",
    "            \"summary\": row.get('Content_Summary', ''),\n",
    "            \"file_name\": row.get('File_Name', 'article'),\n",
    "            \"page_number\": None,\n",
    "            \"table_name\": None,\n",
    "            \"record_id\": None,\n",
    "            \"generation_date\": row.get('Generation_Date', ''),\n",
    "            \"month_year\": row.get('Month_Year', ''),\n",
    "            \"document_version\": 1,\n",
    "            \"load_datetime\": load_datetime\n",
    "        }, axis=1).tolist()\n",
    "\n",
    "        # Upsert news articles into Pinecone\n",
    "        for idx, (text, metadata) in enumerate(zip(texts, metadatas)):\n",
    "            vector_id = f\"article_{idx}\"\n",
    "            try:\n",
    "                # Delete existing vector if it exists\n",
    "                pinecone_store.delete([vector_id])\n",
    "                print(f\"Deleted existing vector with ID {vector_id}.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error deleting vector ID {vector_id}: {e}\")\n",
    "\n",
    "            # Replace None values with empty strings or valid defaults\n",
    "            for key, value in metadata.items():\n",
    "                if value is None:\n",
    "                    metadata[key] = ''\n",
    "\n",
    "            # Upsert the new vector with metadata (excluding text in metadata)\n",
    "            try:\n",
    "                pinecone_store.add_texts(texts=[text], metadatas=[{k: v for k, v in metadata.items() if k != 'content'}], ids=[vector_id])\n",
    "                print(f\"Successfully upserted vector with ID {vector_id} into Pinecone with metadata.\")\n",
    "                metadata_list.append(metadata)\n",
    "            except Exception as e:\n",
    "                print(f\"Error upserting vector ID {vector_id} into Pinecone: {e}\")\n",
    "\n",
    "    # Prepare texts and metadata for additional document if it exists\n",
    "    if additional_document:\n",
    "        text = additional_document.get('content', '')\n",
    "        metadata = {\n",
    "            \"document_type\": additional_document.get('document_type', 'unknown'),\n",
    "            \"title\": additional_document.get('title', ''),\n",
    "            \"author\": additional_document.get('author', ''),\n",
    "            \"source\": additional_document.get('source', ''),\n",
    "            \"published_at\": additional_document.get('published_at', ''),\n",
    "            \"summary\": additional_document.get('summary', ''),\n",
    "            \"file_name\": additional_document.get('file_name', ''),\n",
    "            \"page_number\": additional_document.get('page_number', ''),\n",
    "            \"table_name\": additional_document.get('table_name', ''),\n",
    "            \"record_id\": additional_document.get('record_id', ''),\n",
    "            \"generation_date\": additional_document.get('generation_date', ''),\n",
    "            \"month_year\": additional_document.get('month_year', ''),\n",
    "            \"document_version\": additional_document.get('document_version', 1),\n",
    "            \"load_datetime\": load_datetime\n",
    "        }\n",
    "\n",
    "        vector_id = \"doc_0\"\n",
    "        try:\n",
    "            # Delete existing vector if it exists\n",
    "            pinecone_store.delete([vector_id])\n",
    "            print(f\"Deleted existing vector with ID {vector_id}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting vector ID {vector_id}: {e}\")\n",
    "\n",
    "        # Replace None values with empty strings or valid defaults\n",
    "        for key, value in metadata.items():\n",
    "            if value is None:\n",
    "                metadata[key] = ''\n",
    "\n",
    "        # Upsert the new vector with metadata (excluding text in metadata)\n",
    "        try:\n",
    "            pinecone_store.add_texts(texts=[text], metadatas=[{k: v for k, v in metadata.items() if k != 'content'}], ids=[vector_id])\n",
    "            print(f\"Successfully upserted vector with ID {vector_id} into Pinecone with metadata.\")\n",
    "            metadata_list.append(metadata)\n",
    "        except Exception as e:\n",
    "            print(f\"Error upserting vector ID {vector_id} into Pinecone: {e}\")\n",
    "\n",
    "    # Create DataFrame from metadata\n",
    "    metadata_df = pd.DataFrame(metadata_list)\n",
    "    return metadata_df\n",
    "\n",
    "# Example usage of embed_and_load_to_pinecone\n",
    "additional_document = {}  # No additional document to upload for now\n",
    "\n",
    "# Assuming updated_articles_df and embeddings_model are defined\n",
    "metadata_df = embed_and_load_to_pinecone(updated_articles_df, additional_document, embeddings_model, \"fair-lens\")\n",
    "\n",
    "# Print the metadata DataFrame\n",
    "metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47fa5698-6a2f-483d-b37b-08d231e0db49",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df.to_csv(\"metadata.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c05ebbeb-f36d-4d70-a0b9-7e7c229d20f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore as PineconeStore\n",
    "\n",
    "def similarity_search_in_pinecone(query, pinecone_index_name, embeddings_model, top_k=3):\n",
    "    \"\"\"\n",
    "    Perform similarity search on the Pinecone index.\n",
    "\n",
    "    Parameters:\n",
    "    - query (str): The query to search for similar documents.\n",
    "    - pinecone_index_name (str): The name of the Pinecone index.\n",
    "    - embeddings_model: The embedding model used to create the query embedding.\n",
    "    - top_k (int): The number of top similar documents to return.\n",
    "\n",
    "    Returns:\n",
    "    - List of most similar documents and their metadata.\n",
    "    \"\"\"\n",
    "    # Initialize Pinecone Store\n",
    "    pinecone_store = PineconeStore(index_name=pinecone_index_name, embedding=embeddings_model)\n",
    "\n",
    "    # Perform the similarity search using the query\n",
    "    try:\n",
    "        results = pinecone_store.similarity_search(query=query, k=top_k)\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Error while performing similarity search: {e}\")\n",
    "        return []\n",
    "\n",
    "# Example usage:\n",
    "query_text = \"What are the latest updates on Fair Lending practices?\"\n",
    "results = similarity_search_in_pinecone(query_text, \"fair-lens\", embeddings_model, top_k=5)\n",
    "\n",
    "# Display results\n",
    "for idx, result in enumerate(results, start=1):\n",
    "    print(f\"Result {idx}:\")\n",
    "    print(f\"Title: {result.metadata.get('title')}\")\n",
    "    print(f\"Content: {result.page_content[:200]}...\")  # Displaying first 200 chars of the content for brevity\n",
    "    print(f\"Source: {result.metadata.get('source')}\")\n",
    "    print('-' * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc2e4d0-1544-47b6-a54a-305af8c41709",
   "metadata": {},
   "source": [
    "### Creating a chain for chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ae06829-6a21-46bb-8f63-623eaa906bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=\"\"\"\n",
    "                    You are an Fair Lending chatbot and an expert fair lending and discrimination related issues.\n",
    "                    Use the following pieces of information to answer the user's question.If the user's question is related to an article, and if the\n",
    "                    user has not mentioned which article in any way, then ask him which article and then answer after he responds.\n",
    "                    If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "                    \n",
    "                    Context: {context}\n",
    "                    Question: {question}\n",
    "                    \n",
    "                    Only return the helpful answer below and nothing else.\n",
    "                    Helpful answer:\n",
    "                \"\"\"\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16b17df4-e208-47ed-b500-744a069b3651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"\\n                    You are an Fair Lending chatbot and an expert fair lending and discrimination related issues.\\n                    Use the following pieces of information to answer the user's question.If the user's question is related to an article, and if the\\n                    user has not mentioned which article in any way, then ask him which article and then answer after he responds.\\n                    If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n                    \\n                    Context: {context}\\n                    Question: {question}\\n                    \\n                    Only return the helpful answer below and nothing else.\\n                    Helpful answer:\\n                \")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb322dbb-3296-4b90-8b57-616736201273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['PineconeVectorStore', 'AzureOpenAIEmbeddings'], vectorstore=<langchain_pinecone.vectorstores.PineconeVectorStore object at 0x000001768FC578E0>, search_kwargs={'k': 3})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Pinecone Store\n",
    "pinecone_store = PineconeStore(index_name='fair-lens', embedding=embeddings_model)\n",
    "\n",
    "# Create retriever using PineconeStore\n",
    "retriever = pinecone_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8d45d4a-0d0b-4da3-9a23-745f9a598436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain = (\n",
    "#             {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "#             | PROMPT\n",
    "#             | llm\n",
    "#             | StrOutputParser()\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "206a3cd3-543e-41fd-805b-9b1eaa591832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain.invoke(\"Can you summarize the article with title 'Mortgage access for Black buyers blamed for widening ownership gap'?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d61d70d-cf5e-4c95-920f-749389a0fc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a RetrievalQA chain using LangChain\n",
    "retrieval_qa_chain = RetrievalQA.from_chain_type(\n",
    "                                                    llm=llm,\n",
    "                                                    chain_type=\"stuff\",\n",
    "                                                    retriever=retriever,\n",
    "                                                    chain_type_kwargs={\"prompt\": PROMPT}\n",
    "                                                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7af80f7f-d0d7-43c2-85e0-aaa6d3883ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': \"Can you summarize the article with title 'Mortgage access for Black buyers blamed for widening ownership gap'?\",\n",
       " 'result': \"According to the article 'Mortgage access for Black buyers blamed for widening ownership gap', Black Americans face significant barriers to homeownership due to discriminatory lending practices and lack of access to affordable mortgages. This has resulted in a widening gap in homeownership rates between Black and white Americans.\"}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_qa_chain.invoke(\"Can you summarize the article with title 'Mortgage access for Black buyers blamed for widening ownership gap'?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fbeec0-3cf0-4acd-841e-5d7d765f53c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
